# Practical 1: Introduction to LEX and YACC

**By:** Suhani Gahukar (PRN: 22070521084)  
**Course:** Compiler Construction Lab (T7478)  
**Department:** Computer Science, Symbiosis Institute of Technology  

---

## ðŸŽ¯ Aim:

To study and write a theoretical assignment explaining the structure, purpose, and working of **LEX** and **YACC** compilers.

---

## ðŸ“š Theory:

### ðŸ”¹ LEX (Lexical Analyzer Generator)
- LEX is a tool used to generate **lexical analyzers**, also known as scanners or tokenizers.
- It reads input patterns (tokens like keywords, identifiers, etc.) using **regular expressions** and converts them into C code.
- These patterns are then matched against the input stream to produce tokens for the parser.

### ðŸ”¹ YACC (Yet Another Compiler Compiler)
- YACC is a **parser generator** that takes a grammar specification for a language (usually in BNF format) and produces source code for the parser.
- It typically works alongside LEX, where LEX handles the tokenizing and YACC handles the syntax structure.

### ðŸ”¹ LEX and YACC Integration
- Together, LEX and YACC form a pipeline:
  - LEX â†’ breaks down input into tokens.
  - YACC â†’ arranges these tokens as per defined grammar rules.

### ðŸ”¹ Structure of a LEX Program:
```lex
%{
  // C declarations
%}
%%
  // Rules
%%
  // C main function

```

### ðŸ”¹ Structure of a LEX Program:
```yacc
%{
  // C declarations and header files
%}
%token IDENTIFIER NUMBER
%%
  // Grammar rules
%%
  // C code

```
### ðŸ”¹ Conclusion:
- Gained an understanding of how LEX and YACC automate the process of lexical and syntax analysis in compiler design.
- Understood how to define tokens and grammar rules, and how they interact during compilation.
- Learned that combining LEX and YACC simplifies the development of interpreters and compilers.
